{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mptnzhpy_3C"
      },
      "source": [
        "<center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">به نام خدا</div></center>\n",
        "\n",
        "<h1><center><div style=\"direction:rtl;font-family:B Lotus, B Nazanin, Tahoma\">تمرین عملی 2: طبقه بندی تصاویر Cifar10 با شبکه های کانولوشنالی روی googleColab</div></center></h1>\n",
        "\n",
        "[![Run in Google Colab](https://github.com/Alireza-Akhavan/deeplearning-tensorflow2-notebooks/blob/master/homework/images/colab.png?raw=1)](https://colab.research.google.com/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/homework/ex2-conv-cifar10-in-colab.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ4YTw1py_3D"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">صورت مساله</div>\n",
        "\n",
        "\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "با شبکه های کانولوشنالی آشنا شدیم<br>\n",
        "توصیه می‌شود حتما بعد از تمرین اول این تمرین را حل کنید و قبل از این تمرین نوت بوک زیر را  مرور کنید:\n",
        "</div>\n",
        "\n",
        "[06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb ](https://nbviewer.jupyter.org/github/alireza-akhavan/SRU-deeplearning-workshop/blob/master/06_ConvolutionalNeuralNetwork-Hoda-Keras.ipynb)\n",
        "\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "در این تمرین از مجموعه داده تصویری cifar10 استفاده خواهیم کرد.\n",
        "<br>\n",
        "خیلی از اوقات ممکنه دسترسی به GPU نداشته باشیم. حخوشبختانه سرویس های آنلاین و رایگانی هستند که توان محاسباتی رایگان در اختیارمان میگذراند. در این تمرین از شما خواسته شده که این نوت بوک را در گوگل کولب اجرا کنید.\n",
        "<br>\n",
        " قبلا در مورد گوگل کولب دو پست آموزشی نوشته شده است که در صورت تمایل به کسب اطلاعات بیشتر میتوانید بخوانید.\n",
        "    اما برای اجرا این تمرین نیازی به این جزئیات نخواهید داشت.\n",
        "</div>\n",
        "\n",
        "[آشنایی با سرویس ابری Google Colab ](http://blog.class.vision/1397/02/google-colab/)\n",
        "\n",
        "[اتصال مستقیم سرویس کولب (Google Colab) به درایو (Google Drive) از طریق فایل سیستم FUSE ](http://blog.class.vision/1397/04/%D8%A7%D8%AA%D8%B5%D8%A7%D9%84-%D9%85%D8%B3%D8%AA%D9%82%DB%8C%D9%85-%D8%B3%D8%B1%D9%88%DB%8C%D8%B3-%DA%A9%D9%88%D9%84%D8%A8-google-colab-%D8%A8%D9%87-%D8%AF%D8%B1%D8%A7%DB%8C%D9%88-google-drive/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_JmTCxpy_3E"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">لود کتابخانه های مورد نیاز </div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "کتابخانه های مورد نیاز این تمرین لود شده اند\n",
        "<br>\n",
        "در صورت نیاز میتوانید کتابخانه های بیشتری لود کنید:\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vrKrj1Hwy_3E"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import layers\n",
        "%matplotlib inline\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf6fRW7oy_3F"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">مجموعه داده ی Cifar10 </div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "<br>\n",
        "این مجموعه داده تصاویر رنگی در اندازه ی 32 در 32 و در 10 کلاس مختلف شامل ماشین، کامیون، اسب و ... است که در چارچوب کراس موجود است و از همان استفاده میکنیم.\n",
        "<br>\n",
        "اطلاعات بیشتر در مورد این مجموعه داده را از سایت این مجموعه داده میتوانید مطالعه کنید:\n",
        "<br>\n",
        "</div>\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3UNg150Ny_3F",
        "outputId": "89b5b6f1-3694-4a41-cce3-a89eb0e23d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpeQrRiSy_3F"
      },
      "source": [
        "## <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">نگاهی به مجموعه داده بیندازیم...</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "در زیر تصویری که در اندیس 7-ام این مجموعه داده قرار دارد را مشاهده می‌کنیم. این شماره را را به دلخوه عوض کنید و چند تصویر دیگر این مجموعه داده را ببینید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animals= ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "metadata": {
        "id": "UHLV7xS50sAt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GwQe_BgHy_3F",
        "outputId": "b12fc5e8-9dbf-494a-a6dc-364fdc160c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'horse')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(x_train[7])\n",
        "plt.title (animals[y_train[7][0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krzaec3uy_3F"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 1:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "ماتریس های تصویر را تبدیل به نوع داده ای float32 کنید و مقادیر پیکسل ها را نرمال کنید و بین 0 و 1 بیاورید.\n",
        "<br>\n",
        "<b>راهنمایی: </b>\n",
        "شما باید متد astype را صدا بزنید و در نهایت مقادیر پیکسل ها را تقسیم بر 255 کنید.</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vFOx6W8Ty_3F"
      },
      "outputs": [],
      "source": [
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "6JTD83hx1QOA",
        "outputId": "344c5ada-0796-4ca6-f635-7c16b9c70f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "hSDI_gge9ol5",
        "outputId": "ee84a965-922e-452b-adf0-0de64bdaeeca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJcTcB3Xy_3F"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 2:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "همان طور که میبینید لیبل ها از نوع عددی هستند. آن ها را تبدیل به فرمت one-hot کنید.<br>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w64DUT9fy_3G"
      },
      "source": [
        "<hr>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "تعدادی از لیبل ها قبل از تبدیل به فرمت one-hot:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_MbKIcLjy_3G",
        "outputId": "3bf1e952-6822-4297-934e-65bc58e49e48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       [4],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [7],\n",
              "       [8],\n",
              "       [3]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y_train[0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ynDnWvcyy_3G"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ocKIeE8y_3G"
      },
      "source": [
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "تعدادی از لیبل ها بعد از تبدیل به فرمت one-hot:</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HiC1j1F5y_3G",
        "outputId": "39e58676-c0f0-463a-c472-913f5bd5f722",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.]],\n",
              "\n",
              "       [[1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.],\n",
              "        [1., 0.]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "y_train[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d02WWUdXy_3G"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 3:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "یک شبکه کانولوشنالی با معماری زیر بسازید:\n",
        "<ul>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با32 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه کانولوشنی با64 فیلتر با سایز فیلتر 3x3 و تابع فعالیت relu\n",
        "    </li>\n",
        "    <li>\n",
        "    لایه ی pooling با pool_size=(2,2)\n",
        "    </li>\n",
        "    <li>\n",
        "    استفاده از لایه ی Flatten() . به نظرتون چرا؟\n",
        "    </li>    \n",
        "    <li>\n",
        "    یک لایه Dropout با ترخ 0.5.\n",
        "    </li>\n",
        "    <li>\n",
        "    یک لایه softmax برای احتمالات خروجی. به نظرتون این لایه چند نوران میخواهد؟\n",
        "    </li>    \n",
        "\n",
        "</ul>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "-6BWAJrKy_3G"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trpH4wfOy_3G"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 4:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "مدل را کامپایل کنید و به عنوان optimizer متغیر opt_rms به تابع ارسال کنید. </div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_model():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # First Conv layer\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4), input_shape=(32,32,3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Second Conv layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Third, fourth, fifth convolution layer\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Fully Connected layers\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "MyNva_i1eYgT"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "Gzpvan00iJaT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=False,\n",
        "                            samplewise_center=False,\n",
        "                            featurewise_std_normalization=False,\n",
        "                            samplewise_std_normalization=False,\n",
        "                            zca_whitening=False,\n",
        "                            rotation_range=15,\n",
        "                            width_shift_range=0.1,\n",
        "                            height_shift_range=0.1,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=False)\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "l6LTV6CDh9WL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import  Adam"
      ],
      "metadata": {
        "id": "B0e_9ztvgGgu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(learning_rate=0.0003),\n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3xrZuIV7fyAk",
        "outputId": "3e36ee26-0709-48e0-f353-411b1ffda902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-8bd4e832ca63>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(loss='categorical_crossentropy',\n\u001b[0m\u001b[1;32m      2\u001b[0m              \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m              metrics=['accuracy'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 64),\n",
        "                    steps_per_epoch = len(x_train) // 64,\n",
        "                    epochs = 125,\n",
        "                    validation_data= (x_test, y_test),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "id": "zT9Px9tvhicg",
        "outputId": "c61fe956-82e3-4726-b030-29c66741613c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f1a612655ed0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit_generator(datagen.flow(x_train, y_train, batch_size = 64),\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     verbose=1)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "d4iRMFgTy_3G"
      },
      "outputs": [],
      "source": [
        "opt_rms = keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6BCC6Pwy_3H"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 5:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "با فراخوانی متد fit روی مدل آن را آموزش بدهید. برای سادگی25 ایپاک با سایز بچ 64 بزنید.\n",
        "    <br>\n",
        " به عنوان دیتای validation نیز x_test و y_test را ارسال کنید که در هر سری کارایی روی داده های تست اعلام شود.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "4Uke36pKy_3H",
        "outputId": "ca2dffb2-894d-40ca-a2a9-061c6f2b0e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "391/391 [==============================] - 5s 9ms/step - loss: 1.9925 - accuracy: 0.2661 - val_loss: 1.6598 - val_accuracy: 0.4010\n",
            "Epoch 2/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 1.6722 - accuracy: 0.3978 - val_loss: 1.4439 - val_accuracy: 0.4888\n",
            "Epoch 3/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.5207 - accuracy: 0.4539 - val_loss: 1.4254 - val_accuracy: 0.4821\n",
            "Epoch 4/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.4290 - accuracy: 0.4884 - val_loss: 1.2568 - val_accuracy: 0.5599\n",
            "Epoch 5/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.3503 - accuracy: 0.5189 - val_loss: 1.1988 - val_accuracy: 0.5668\n",
            "Epoch 6/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.2862 - accuracy: 0.5456 - val_loss: 1.1841 - val_accuracy: 0.5766\n",
            "Epoch 7/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.2337 - accuracy: 0.5647 - val_loss: 1.1139 - val_accuracy: 0.6053\n",
            "Epoch 8/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1791 - accuracy: 0.5829 - val_loss: 1.1669 - val_accuracy: 0.5846\n",
            "Epoch 9/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1423 - accuracy: 0.5999 - val_loss: 1.1184 - val_accuracy: 0.6015\n",
            "Epoch 10/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.1013 - accuracy: 0.6159 - val_loss: 1.0781 - val_accuracy: 0.6163\n",
            "Epoch 11/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0705 - accuracy: 0.6280 - val_loss: 1.0976 - val_accuracy: 0.6111\n",
            "Epoch 12/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 1.0369 - accuracy: 0.6406 - val_loss: 1.0270 - val_accuracy: 0.6440\n",
            "Epoch 13/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 1.0108 - accuracy: 0.6490 - val_loss: 1.1212 - val_accuracy: 0.6147\n",
            "Epoch 14/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9837 - accuracy: 0.6593 - val_loss: 0.9851 - val_accuracy: 0.6603\n",
            "Epoch 15/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9668 - accuracy: 0.6652 - val_loss: 1.0495 - val_accuracy: 0.6426\n",
            "Epoch 16/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9463 - accuracy: 0.6728 - val_loss: 0.9228 - val_accuracy: 0.6766\n",
            "Epoch 17/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.9295 - accuracy: 0.6792 - val_loss: 0.9907 - val_accuracy: 0.6587\n",
            "Epoch 18/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.9145 - accuracy: 0.6836 - val_loss: 0.9600 - val_accuracy: 0.6687\n",
            "Epoch 19/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8960 - accuracy: 0.6915 - val_loss: 0.9234 - val_accuracy: 0.6856\n",
            "Epoch 20/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8751 - accuracy: 0.6957 - val_loss: 0.9651 - val_accuracy: 0.6766\n",
            "Epoch 21/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8671 - accuracy: 0.7001 - val_loss: 0.8856 - val_accuracy: 0.6953\n",
            "Epoch 22/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8518 - accuracy: 0.7041 - val_loss: 0.9435 - val_accuracy: 0.6810\n",
            "Epoch 23/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8343 - accuracy: 0.7084 - val_loss: 0.9784 - val_accuracy: 0.6703\n",
            "Epoch 24/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8200 - accuracy: 0.7173 - val_loss: 0.9242 - val_accuracy: 0.6918\n",
            "Epoch 25/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.8145 - accuracy: 0.7196 - val_loss: 0.9074 - val_accuracy: 0.6951\n",
            "Epoch 26/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.8065 - accuracy: 0.7202 - val_loss: 0.9427 - val_accuracy: 0.6895\n",
            "Epoch 27/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7907 - accuracy: 0.7271 - val_loss: 0.9329 - val_accuracy: 0.6856\n",
            "Epoch 28/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7828 - accuracy: 0.7281 - val_loss: 0.8831 - val_accuracy: 0.7013\n",
            "Epoch 29/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7736 - accuracy: 0.7311 - val_loss: 0.8997 - val_accuracy: 0.7010\n",
            "Epoch 30/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7665 - accuracy: 0.7341 - val_loss: 0.9293 - val_accuracy: 0.6935\n",
            "Epoch 31/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7573 - accuracy: 0.7387 - val_loss: 0.8776 - val_accuracy: 0.7049\n",
            "Epoch 32/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7489 - accuracy: 0.7397 - val_loss: 0.8921 - val_accuracy: 0.7086\n",
            "Epoch 33/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7448 - accuracy: 0.7417 - val_loss: 0.9405 - val_accuracy: 0.6965\n",
            "Epoch 34/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7377 - accuracy: 0.7462 - val_loss: 0.9470 - val_accuracy: 0.6822\n",
            "Epoch 35/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7291 - accuracy: 0.7459 - val_loss: 0.9735 - val_accuracy: 0.6803\n",
            "Epoch 36/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7312 - accuracy: 0.7462 - val_loss: 0.9385 - val_accuracy: 0.6934\n",
            "Epoch 37/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7253 - accuracy: 0.7494 - val_loss: 1.0104 - val_accuracy: 0.6920\n",
            "Epoch 38/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7141 - accuracy: 0.7514 - val_loss: 1.0181 - val_accuracy: 0.6907\n",
            "Epoch 39/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7102 - accuracy: 0.7533 - val_loss: 0.9452 - val_accuracy: 0.6955\n",
            "Epoch 40/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7064 - accuracy: 0.7529 - val_loss: 0.9795 - val_accuracy: 0.6985\n",
            "Epoch 41/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7068 - accuracy: 0.7571 - val_loss: 0.8997 - val_accuracy: 0.7116\n",
            "Epoch 42/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7011 - accuracy: 0.7556 - val_loss: 0.9596 - val_accuracy: 0.6947\n",
            "Epoch 43/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6981 - accuracy: 0.7589 - val_loss: 0.9995 - val_accuracy: 0.6985\n",
            "Epoch 44/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6927 - accuracy: 0.7594 - val_loss: 0.9726 - val_accuracy: 0.6964\n",
            "Epoch 45/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6864 - accuracy: 0.7616 - val_loss: 1.0481 - val_accuracy: 0.6819\n",
            "Epoch 46/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6841 - accuracy: 0.7621 - val_loss: 0.9845 - val_accuracy: 0.7033\n",
            "Epoch 47/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6856 - accuracy: 0.7613 - val_loss: 1.0179 - val_accuracy: 0.6959\n",
            "Epoch 48/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6825 - accuracy: 0.7623 - val_loss: 0.9742 - val_accuracy: 0.7004\n",
            "Epoch 49/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6820 - accuracy: 0.7630 - val_loss: 0.9679 - val_accuracy: 0.7038\n",
            "Epoch 50/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6753 - accuracy: 0.7643 - val_loss: 1.0708 - val_accuracy: 0.7064\n",
            "Epoch 51/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6752 - accuracy: 0.7649 - val_loss: 1.0525 - val_accuracy: 0.6874\n",
            "Epoch 52/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6714 - accuracy: 0.7670 - val_loss: 1.0602 - val_accuracy: 0.7018\n",
            "Epoch 53/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6648 - accuracy: 0.7665 - val_loss: 1.0864 - val_accuracy: 0.6907\n",
            "Epoch 54/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6631 - accuracy: 0.7689 - val_loss: 0.9919 - val_accuracy: 0.7056\n",
            "Epoch 55/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6665 - accuracy: 0.7692 - val_loss: 1.1077 - val_accuracy: 0.6775\n",
            "Epoch 56/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6634 - accuracy: 0.7684 - val_loss: 1.0021 - val_accuracy: 0.7060\n",
            "Epoch 57/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6570 - accuracy: 0.7711 - val_loss: 1.1530 - val_accuracy: 0.6959\n",
            "Epoch 58/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6641 - accuracy: 0.7688 - val_loss: 1.0648 - val_accuracy: 0.6959\n",
            "Epoch 59/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6569 - accuracy: 0.7737 - val_loss: 1.1551 - val_accuracy: 0.7028\n",
            "Epoch 60/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6575 - accuracy: 0.7708 - val_loss: 1.1862 - val_accuracy: 0.6928\n",
            "Epoch 61/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.7720 - val_loss: 1.3360 - val_accuracy: 0.6872\n",
            "Epoch 62/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6654 - accuracy: 0.7699 - val_loss: 1.0804 - val_accuracy: 0.7014\n",
            "Epoch 63/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6569 - accuracy: 0.7711 - val_loss: 1.0346 - val_accuracy: 0.6911\n",
            "Epoch 64/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6504 - accuracy: 0.7746 - val_loss: 1.2403 - val_accuracy: 0.7057\n",
            "Epoch 65/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6647 - accuracy: 0.7696 - val_loss: 1.0999 - val_accuracy: 0.7101\n",
            "Epoch 66/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6482 - accuracy: 0.7768 - val_loss: 1.1710 - val_accuracy: 0.7019\n",
            "Epoch 67/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6561 - accuracy: 0.7732 - val_loss: 0.9980 - val_accuracy: 0.6878\n",
            "Epoch 68/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6487 - accuracy: 0.7740 - val_loss: 1.0198 - val_accuracy: 0.6998\n",
            "Epoch 69/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6519 - accuracy: 0.7738 - val_loss: 1.1598 - val_accuracy: 0.7001\n",
            "Epoch 70/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6515 - accuracy: 0.7730 - val_loss: 1.1557 - val_accuracy: 0.7044\n",
            "Epoch 71/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6429 - accuracy: 0.7756 - val_loss: 1.1696 - val_accuracy: 0.6511\n",
            "Epoch 72/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6498 - accuracy: 0.7736 - val_loss: 1.1614 - val_accuracy: 0.7091\n",
            "Epoch 73/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6522 - accuracy: 0.7734 - val_loss: 1.1753 - val_accuracy: 0.6907\n",
            "Epoch 74/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6434 - accuracy: 0.7750 - val_loss: 1.0836 - val_accuracy: 0.7001\n",
            "Epoch 75/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6548 - accuracy: 0.7755 - val_loss: 1.2555 - val_accuracy: 0.6705\n",
            "Epoch 76/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6503 - accuracy: 0.7771 - val_loss: 1.3706 - val_accuracy: 0.6915\n",
            "Epoch 77/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6442 - accuracy: 0.7765 - val_loss: 1.3203 - val_accuracy: 0.6966\n",
            "Epoch 78/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6490 - accuracy: 0.7750 - val_loss: 1.1675 - val_accuracy: 0.6905\n",
            "Epoch 79/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6482 - accuracy: 0.7762 - val_loss: 1.3573 - val_accuracy: 0.6687\n",
            "Epoch 80/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6495 - accuracy: 0.7762 - val_loss: 1.2373 - val_accuracy: 0.6919\n",
            "Epoch 81/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6519 - accuracy: 0.7756 - val_loss: 1.3405 - val_accuracy: 0.7039\n",
            "Epoch 82/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6466 - accuracy: 0.7765 - val_loss: 1.1823 - val_accuracy: 0.6959\n",
            "Epoch 83/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6449 - accuracy: 0.7781 - val_loss: 1.2390 - val_accuracy: 0.6876\n",
            "Epoch 84/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6499 - accuracy: 0.7756 - val_loss: 1.4075 - val_accuracy: 0.6971\n",
            "Epoch 85/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6497 - accuracy: 0.7773 - val_loss: 1.3254 - val_accuracy: 0.6856\n",
            "Epoch 86/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6525 - accuracy: 0.7770 - val_loss: 1.3184 - val_accuracy: 0.6982\n",
            "Epoch 87/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6508 - accuracy: 0.7769 - val_loss: 1.3413 - val_accuracy: 0.6745\n",
            "Epoch 88/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6507 - accuracy: 0.7752 - val_loss: 1.2695 - val_accuracy: 0.6833\n",
            "Epoch 89/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.7756 - val_loss: 1.2719 - val_accuracy: 0.6992\n",
            "Epoch 90/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.7732 - val_loss: 1.2023 - val_accuracy: 0.6751\n",
            "Epoch 91/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6567 - accuracy: 0.7755 - val_loss: 1.1712 - val_accuracy: 0.6605\n",
            "Epoch 92/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6590 - accuracy: 0.7740 - val_loss: 1.3727 - val_accuracy: 0.6879\n",
            "Epoch 93/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6553 - accuracy: 0.7764 - val_loss: 1.2637 - val_accuracy: 0.6911\n",
            "Epoch 94/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6554 - accuracy: 0.7747 - val_loss: 1.2023 - val_accuracy: 0.6924\n",
            "Epoch 95/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6603 - accuracy: 0.7749 - val_loss: 1.4008 - val_accuracy: 0.7014\n",
            "Epoch 96/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6554 - accuracy: 0.7751 - val_loss: 1.3999 - val_accuracy: 0.6845\n",
            "Epoch 97/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6552 - accuracy: 0.7763 - val_loss: 1.1856 - val_accuracy: 0.6771\n",
            "Epoch 98/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6546 - accuracy: 0.7746 - val_loss: 1.3725 - val_accuracy: 0.6901\n",
            "Epoch 99/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6628 - accuracy: 0.7732 - val_loss: 1.3910 - val_accuracy: 0.7083\n",
            "Epoch 100/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6612 - accuracy: 0.7738 - val_loss: 1.4158 - val_accuracy: 0.6925\n",
            "Epoch 101/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6602 - accuracy: 0.7730 - val_loss: 1.7069 - val_accuracy: 0.6948\n",
            "Epoch 102/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6610 - accuracy: 0.7748 - val_loss: 1.5511 - val_accuracy: 0.6974\n",
            "Epoch 103/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6582 - accuracy: 0.7748 - val_loss: 1.1345 - val_accuracy: 0.6297\n",
            "Epoch 104/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6625 - accuracy: 0.7722 - val_loss: 1.6916 - val_accuracy: 0.6921\n",
            "Epoch 105/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6668 - accuracy: 0.7725 - val_loss: 1.3977 - val_accuracy: 0.6858\n",
            "Epoch 106/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6626 - accuracy: 0.7709 - val_loss: 1.6114 - val_accuracy: 0.6920\n",
            "Epoch 107/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6695 - accuracy: 0.7711 - val_loss: 1.2585 - val_accuracy: 0.6762\n",
            "Epoch 108/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6674 - accuracy: 0.7710 - val_loss: 1.2356 - val_accuracy: 0.6866\n",
            "Epoch 109/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6636 - accuracy: 0.7729 - val_loss: 1.2072 - val_accuracy: 0.6778\n",
            "Epoch 110/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6671 - accuracy: 0.7736 - val_loss: 1.4052 - val_accuracy: 0.7052\n",
            "Epoch 111/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6803 - accuracy: 0.7694 - val_loss: 1.6116 - val_accuracy: 0.6858\n",
            "Epoch 112/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6746 - accuracy: 0.7728 - val_loss: 1.2704 - val_accuracy: 0.6253\n",
            "Epoch 113/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6739 - accuracy: 0.7704 - val_loss: 1.3549 - val_accuracy: 0.6820\n",
            "Epoch 114/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6718 - accuracy: 0.7698 - val_loss: 1.9379 - val_accuracy: 0.6895\n",
            "Epoch 115/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6693 - accuracy: 0.7727 - val_loss: 1.7125 - val_accuracy: 0.6725\n",
            "Epoch 116/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6713 - accuracy: 0.7711 - val_loss: 1.3527 - val_accuracy: 0.6639\n",
            "Epoch 117/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6817 - accuracy: 0.7685 - val_loss: 1.4161 - val_accuracy: 0.6971\n",
            "Epoch 118/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6834 - accuracy: 0.7691 - val_loss: 1.3347 - val_accuracy: 0.6821\n",
            "Epoch 119/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6891 - accuracy: 0.7652 - val_loss: 1.4646 - val_accuracy: 0.6901\n",
            "Epoch 120/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.6797 - accuracy: 0.7704 - val_loss: 1.1849 - val_accuracy: 0.6708\n",
            "Epoch 121/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6854 - accuracy: 0.7688 - val_loss: 1.5719 - val_accuracy: 0.6291\n",
            "Epoch 122/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6868 - accuracy: 0.7714 - val_loss: 1.3351 - val_accuracy: 0.6794\n",
            "Epoch 123/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6771 - accuracy: 0.7716 - val_loss: 1.8243 - val_accuracy: 0.6566\n",
            "Epoch 124/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6886 - accuracy: 0.7677 - val_loss: 1.4432 - val_accuracy: 0.6868\n",
            "Epoch 125/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6849 - accuracy: 0.7698 - val_loss: 1.1594 - val_accuracy: 0.6341\n",
            "Epoch 126/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6930 - accuracy: 0.7658 - val_loss: 1.4230 - val_accuracy: 0.6481\n",
            "Epoch 127/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.6884 - accuracy: 0.7674 - val_loss: 1.3146 - val_accuracy: 0.6713\n",
            "Epoch 128/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6878 - accuracy: 0.7666 - val_loss: 1.2963 - val_accuracy: 0.6939\n",
            "Epoch 129/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6928 - accuracy: 0.7660 - val_loss: 1.5988 - val_accuracy: 0.6241\n",
            "Epoch 130/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7002 - accuracy: 0.7659 - val_loss: 1.4423 - val_accuracy: 0.6873\n",
            "Epoch 131/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6990 - accuracy: 0.7642 - val_loss: 1.6739 - val_accuracy: 0.6885\n",
            "Epoch 132/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6915 - accuracy: 0.7656 - val_loss: 1.3478 - val_accuracy: 0.6958\n",
            "Epoch 133/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6959 - accuracy: 0.7670 - val_loss: 1.6177 - val_accuracy: 0.6714\n",
            "Epoch 134/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.6997 - accuracy: 0.7668 - val_loss: 1.5674 - val_accuracy: 0.6987\n",
            "Epoch 135/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7058 - accuracy: 0.7647 - val_loss: 2.1209 - val_accuracy: 0.6443\n",
            "Epoch 136/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.6902 - accuracy: 0.7648 - val_loss: 1.3665 - val_accuracy: 0.6772\n",
            "Epoch 137/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7060 - accuracy: 0.7634 - val_loss: 1.8405 - val_accuracy: 0.6578\n",
            "Epoch 138/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7024 - accuracy: 0.7635 - val_loss: 1.3856 - val_accuracy: 0.6981\n",
            "Epoch 139/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7111 - accuracy: 0.7605 - val_loss: 1.1643 - val_accuracy: 0.6519\n",
            "Epoch 140/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7050 - accuracy: 0.7623 - val_loss: 1.4926 - val_accuracy: 0.6868\n",
            "Epoch 141/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7162 - accuracy: 0.7608 - val_loss: 1.6120 - val_accuracy: 0.6858\n",
            "Epoch 142/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7146 - accuracy: 0.7615 - val_loss: 1.3528 - val_accuracy: 0.6629\n",
            "Epoch 143/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7173 - accuracy: 0.7616 - val_loss: 1.7397 - val_accuracy: 0.6935\n",
            "Epoch 144/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7151 - accuracy: 0.7594 - val_loss: 1.5115 - val_accuracy: 0.6454\n",
            "Epoch 145/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7173 - accuracy: 0.7602 - val_loss: 1.2470 - val_accuracy: 0.6781\n",
            "Epoch 146/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7170 - accuracy: 0.7617 - val_loss: 1.2692 - val_accuracy: 0.6346\n",
            "Epoch 147/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7218 - accuracy: 0.7570 - val_loss: 1.4113 - val_accuracy: 0.6778\n",
            "Epoch 148/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7217 - accuracy: 0.7592 - val_loss: 1.3370 - val_accuracy: 0.6851\n",
            "Epoch 149/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7246 - accuracy: 0.7577 - val_loss: 1.2366 - val_accuracy: 0.6812\n",
            "Epoch 150/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7391 - accuracy: 0.7532 - val_loss: 1.3262 - val_accuracy: 0.6856\n",
            "Epoch 151/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7146 - accuracy: 0.7618 - val_loss: 1.6892 - val_accuracy: 0.6397\n",
            "Epoch 152/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7312 - accuracy: 0.7575 - val_loss: 1.3533 - val_accuracy: 0.6657\n",
            "Epoch 153/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7398 - accuracy: 0.7559 - val_loss: 1.8004 - val_accuracy: 0.6716\n",
            "Epoch 154/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7275 - accuracy: 0.7565 - val_loss: 1.3812 - val_accuracy: 0.6661\n",
            "Epoch 155/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7240 - accuracy: 0.7597 - val_loss: 1.7337 - val_accuracy: 0.6404\n",
            "Epoch 156/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7457 - accuracy: 0.7535 - val_loss: 1.4048 - val_accuracy: 0.6951\n",
            "Epoch 157/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7385 - accuracy: 0.7553 - val_loss: 1.7410 - val_accuracy: 0.6833\n",
            "Epoch 158/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7152 - accuracy: 0.7595 - val_loss: 1.7213 - val_accuracy: 0.6689\n",
            "Epoch 159/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7320 - accuracy: 0.7554 - val_loss: 1.3127 - val_accuracy: 0.6539\n",
            "Epoch 160/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7401 - accuracy: 0.7572 - val_loss: 1.3476 - val_accuracy: 0.6755\n",
            "Epoch 161/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7221 - accuracy: 0.7589 - val_loss: 1.5709 - val_accuracy: 0.6285\n",
            "Epoch 162/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7327 - accuracy: 0.7549 - val_loss: 1.5673 - val_accuracy: 0.6558\n",
            "Epoch 163/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7498 - accuracy: 0.7533 - val_loss: 1.3552 - val_accuracy: 0.6578\n",
            "Epoch 164/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7356 - accuracy: 0.7543 - val_loss: 1.4092 - val_accuracy: 0.6865\n",
            "Epoch 165/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7331 - accuracy: 0.7549 - val_loss: 1.6907 - val_accuracy: 0.6961\n",
            "Epoch 166/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7452 - accuracy: 0.7539 - val_loss: 1.5850 - val_accuracy: 0.6766\n",
            "Epoch 167/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7335 - accuracy: 0.7554 - val_loss: 1.3054 - val_accuracy: 0.6805\n",
            "Epoch 168/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7267 - accuracy: 0.7565 - val_loss: 1.7573 - val_accuracy: 0.6929\n",
            "Epoch 169/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7382 - accuracy: 0.7567 - val_loss: 1.5258 - val_accuracy: 0.6760\n",
            "Epoch 170/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7336 - accuracy: 0.7566 - val_loss: 1.4599 - val_accuracy: 0.6765\n",
            "Epoch 171/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7301 - accuracy: 0.7569 - val_loss: 1.3196 - val_accuracy: 0.6916\n",
            "Epoch 172/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7298 - accuracy: 0.7566 - val_loss: 1.3879 - val_accuracy: 0.6626\n",
            "Epoch 173/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7387 - accuracy: 0.7557 - val_loss: 1.2082 - val_accuracy: 0.6831\n",
            "Epoch 174/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7342 - accuracy: 0.7540 - val_loss: 1.3650 - val_accuracy: 0.6947\n",
            "Epoch 175/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7381 - accuracy: 0.7550 - val_loss: 1.5067 - val_accuracy: 0.6974\n",
            "Epoch 176/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7365 - accuracy: 0.7572 - val_loss: 1.5842 - val_accuracy: 0.6713\n",
            "Epoch 177/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7430 - accuracy: 0.7512 - val_loss: 1.5942 - val_accuracy: 0.6918\n",
            "Epoch 178/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7451 - accuracy: 0.7520 - val_loss: 1.5025 - val_accuracy: 0.6955\n",
            "Epoch 179/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7309 - accuracy: 0.7589 - val_loss: 1.4917 - val_accuracy: 0.6824\n",
            "Epoch 180/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7341 - accuracy: 0.7568 - val_loss: 1.4535 - val_accuracy: 0.6457\n",
            "Epoch 181/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7424 - accuracy: 0.7542 - val_loss: 1.2849 - val_accuracy: 0.6593\n",
            "Epoch 182/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7441 - accuracy: 0.7538 - val_loss: 1.3022 - val_accuracy: 0.6850\n",
            "Epoch 183/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7384 - accuracy: 0.7539 - val_loss: 1.5165 - val_accuracy: 0.6757\n",
            "Epoch 184/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7412 - accuracy: 0.7555 - val_loss: 1.4950 - val_accuracy: 0.6918\n",
            "Epoch 185/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7497 - accuracy: 0.7516 - val_loss: 1.4019 - val_accuracy: 0.6948\n",
            "Epoch 186/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7331 - accuracy: 0.7561 - val_loss: 1.3967 - val_accuracy: 0.7014\n",
            "Epoch 187/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7315 - accuracy: 0.7561 - val_loss: 1.9329 - val_accuracy: 0.6697\n",
            "Epoch 188/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7273 - accuracy: 0.7576 - val_loss: 1.5208 - val_accuracy: 0.6417\n",
            "Epoch 189/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7364 - accuracy: 0.7566 - val_loss: 1.6179 - val_accuracy: 0.6922\n",
            "Epoch 190/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7273 - accuracy: 0.7564 - val_loss: 1.4653 - val_accuracy: 0.6522\n",
            "Epoch 191/200\n",
            "391/391 [==============================] - 3s 6ms/step - loss: 0.7323 - accuracy: 0.7552 - val_loss: 1.2758 - val_accuracy: 0.6735\n",
            "Epoch 192/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7357 - accuracy: 0.7563 - val_loss: 1.5622 - val_accuracy: 0.6820\n",
            "Epoch 193/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7267 - accuracy: 0.7561 - val_loss: 1.6200 - val_accuracy: 0.6147\n",
            "Epoch 194/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7327 - accuracy: 0.7567 - val_loss: 1.8417 - val_accuracy: 0.6684\n",
            "Epoch 195/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7356 - accuracy: 0.7567 - val_loss: 1.3785 - val_accuracy: 0.6101\n",
            "Epoch 196/200\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.7428 - accuracy: 0.7556 - val_loss: 1.4439 - val_accuracy: 0.6875\n",
            "Epoch 197/200\n",
            "391/391 [==============================] - 3s 8ms/step - loss: 0.7352 - accuracy: 0.7552 - val_loss: 1.2894 - val_accuracy: 0.6486\n",
            "Epoch 198/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7453 - accuracy: 0.7520 - val_loss: 1.4542 - val_accuracy: 0.6530\n",
            "Epoch 199/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7311 - accuracy: 0.7552 - val_loss: 1.4842 - val_accuracy: 0.6756\n",
            "Epoch 200/200\n",
            "391/391 [==============================] - 2s 6ms/step - loss: 0.7315 - accuracy: 0.7577 - val_loss: 1.3295 - val_accuracy: 0.6841\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt_rms,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# 7. Fit model on training data\n",
        "history = model.fit(x_train, y_train, epochs=200, batch_size=128,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWXSLwdy_3H"
      },
      "source": [
        "# <div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\">سوال 6:</div>\n",
        "<div style=\"direction:rtl;text-align:right;font-family:Tahoma\">\n",
        "شبکه و هایپرپارامترهای این شبکه را به هر نحوی دوست دارید تغییر دهید تا دقت روی دادگان تست را به حداکثر برسانید.\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "id": "cC7FuMQw9Rae",
        "outputId": "ac1053e0-fab2-4fc9-baed-a31cc6606529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/128.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/128.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.9/128.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.11.17)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner  as kt\n",
        "import keras"
      ],
      "metadata": {
        "id": "BKNQa5Xd9uX2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_builder(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Flatten(input_shape=(32, 32,3)))\n",
        "\n",
        "  # Tune the number of units in the first Dense layer\n",
        "  # Choose an optimal value between 32-512\n",
        "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "  model.add(keras.layers.Dense(10))\n",
        "\n",
        "  # Tune the learning rate for the optimizer\n",
        "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
        "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "TLyBhAG4BXl5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Dense(\n",
        "      hp.Choice('units', [8, 16, 32]),\n",
        "      activation='relu'))\n",
        "  model.add(keras.layers.Dense(1, activation='relu'))\n",
        "  model.compile(loss='sparse_categorical_crossentropy')\n",
        "  return model"
      ],
      "metadata": {
        "id": "_1yso6I-96v-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=50,\n",
        "                     factor=3,\n",
        "\n",
        "                     project_name='intro_to_kt')"
      ],
      "metadata": {
        "id": "8tysrO_gB2XB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
      ],
      "metadata": {
        "id": "1S8IyqA5CO6p"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "id": "66Lr7wUlHkBV",
        "outputId": "57b5c38a-79a5-411a-96c7-76b25a936316",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "id": "fzFb_uGhHpob",
        "outputId": "6663814b-3c2f-49df-bf5b-0c985d8a470b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "PuuwiMVkJQQm",
        "outputId": "698baaf6-8185-43ba-aed7-a8b001d84763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "id": "KGxHwyM6JVuc",
        "outputId": "3ab4ae02-2491-4e8b-d1e6-3a97fa69f62e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train[0:10]"
      ],
      "metadata": {
        "id": "foQHwYDqJEwy",
        "outputId": "732d4b77-29ad-4f71-8740-1be04d707c0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.23137255, 0.24313726, 0.24705882],\n",
              "         [0.16862746, 0.18039216, 0.1764706 ],\n",
              "         [0.19607843, 0.1882353 , 0.16862746],\n",
              "         ...,\n",
              "         [0.61960787, 0.5176471 , 0.42352942],\n",
              "         [0.59607846, 0.49019608, 0.4       ],\n",
              "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
              "\n",
              "        [[0.0627451 , 0.07843138, 0.07843138],\n",
              "         [0.        , 0.        , 0.        ],\n",
              "         [0.07058824, 0.03137255, 0.        ],\n",
              "         ...,\n",
              "         [0.48235294, 0.34509805, 0.21568628],\n",
              "         [0.46666667, 0.3254902 , 0.19607843],\n",
              "         [0.47843137, 0.34117648, 0.22352941]],\n",
              "\n",
              "        [[0.09803922, 0.09411765, 0.08235294],\n",
              "         [0.0627451 , 0.02745098, 0.        ],\n",
              "         [0.19215687, 0.10588235, 0.03137255],\n",
              "         ...,\n",
              "         [0.4627451 , 0.32941177, 0.19607843],\n",
              "         [0.47058824, 0.32941177, 0.19607843],\n",
              "         [0.42745098, 0.28627452, 0.16470589]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
              "         [0.7882353 , 0.6       , 0.13333334],\n",
              "         [0.7764706 , 0.6313726 , 0.10196079],\n",
              "         ...,\n",
              "         [0.627451  , 0.52156866, 0.27450982],\n",
              "         [0.21960784, 0.12156863, 0.02745098],\n",
              "         [0.20784314, 0.13333334, 0.07843138]],\n",
              "\n",
              "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
              "         [0.6784314 , 0.48235294, 0.16470589],\n",
              "         [0.7294118 , 0.5647059 , 0.11764706],\n",
              "         ...,\n",
              "         [0.72156864, 0.5803922 , 0.36862746],\n",
              "         [0.38039216, 0.24313726, 0.13333334],\n",
              "         [0.3254902 , 0.20784314, 0.13333334]],\n",
              "\n",
              "        [[0.69411767, 0.5647059 , 0.45490196],\n",
              "         [0.65882355, 0.5058824 , 0.36862746],\n",
              "         [0.7019608 , 0.5568628 , 0.34117648],\n",
              "         ...,\n",
              "         [0.84705883, 0.72156864, 0.54901963],\n",
              "         [0.5921569 , 0.4627451 , 0.32941177],\n",
              "         [0.48235294, 0.36078432, 0.28235295]]],\n",
              "\n",
              "\n",
              "       [[[0.6039216 , 0.69411767, 0.73333335],\n",
              "         [0.49411765, 0.5372549 , 0.53333336],\n",
              "         [0.4117647 , 0.40784314, 0.37254903],\n",
              "         ...,\n",
              "         [0.35686275, 0.37254903, 0.2784314 ],\n",
              "         [0.34117648, 0.3529412 , 0.2784314 ],\n",
              "         [0.30980393, 0.31764707, 0.27450982]],\n",
              "\n",
              "        [[0.54901963, 0.627451  , 0.6627451 ],\n",
              "         [0.5686275 , 0.6       , 0.6039216 ],\n",
              "         [0.49019608, 0.49019608, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.3764706 , 0.3882353 , 0.30588236],\n",
              "         [0.3019608 , 0.3137255 , 0.24313726],\n",
              "         [0.2784314 , 0.28627452, 0.23921569]],\n",
              "\n",
              "        [[0.54901963, 0.60784316, 0.6431373 ],\n",
              "         [0.54509807, 0.57254905, 0.58431375],\n",
              "         [0.4509804 , 0.4509804 , 0.4392157 ],\n",
              "         ...,\n",
              "         [0.30980393, 0.32156864, 0.2509804 ],\n",
              "         [0.26666668, 0.27450982, 0.21568628],\n",
              "         [0.2627451 , 0.27058825, 0.21568628]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.6862745 , 0.654902  , 0.6509804 ],\n",
              "         [0.6117647 , 0.6039216 , 0.627451  ],\n",
              "         [0.6039216 , 0.627451  , 0.6666667 ],\n",
              "         ...,\n",
              "         [0.16470589, 0.13333334, 0.14117648],\n",
              "         [0.23921569, 0.20784314, 0.22352941],\n",
              "         [0.3647059 , 0.3254902 , 0.35686275]],\n",
              "\n",
              "        [[0.64705884, 0.6039216 , 0.5019608 ],\n",
              "         [0.6117647 , 0.59607846, 0.50980395],\n",
              "         [0.62352943, 0.6313726 , 0.5568628 ],\n",
              "         ...,\n",
              "         [0.40392157, 0.3647059 , 0.3764706 ],\n",
              "         [0.48235294, 0.44705883, 0.47058824],\n",
              "         [0.5137255 , 0.4745098 , 0.5137255 ]],\n",
              "\n",
              "        [[0.6392157 , 0.5803922 , 0.47058824],\n",
              "         [0.61960787, 0.5803922 , 0.47843137],\n",
              "         [0.6392157 , 0.6117647 , 0.52156866],\n",
              "         ...,\n",
              "         [0.56078434, 0.52156866, 0.54509807],\n",
              "         [0.56078434, 0.5254902 , 0.5568628 ],\n",
              "         [0.56078434, 0.52156866, 0.5647059 ]]],\n",
              "\n",
              "\n",
              "       [[[1.        , 1.        , 1.        ],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         ...,\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686],\n",
              "         [0.99215686, 0.99215686, 0.99215686]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[1.        , 1.        , 1.        ],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         ...,\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843],\n",
              "         [0.99607843, 0.99607843, 0.99607843]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.44313726, 0.47058824, 0.4392157 ],\n",
              "         [0.43529412, 0.4627451 , 0.43529412],\n",
              "         [0.4117647 , 0.4392157 , 0.41568628],\n",
              "         ...,\n",
              "         [0.28235295, 0.31764707, 0.3137255 ],\n",
              "         [0.28235295, 0.3137255 , 0.30980393],\n",
              "         [0.28235295, 0.3137255 , 0.30980393]],\n",
              "\n",
              "        [[0.43529412, 0.4627451 , 0.43137255],\n",
              "         [0.40784314, 0.43529412, 0.40784314],\n",
              "         [0.3882353 , 0.41568628, 0.38431373],\n",
              "         ...,\n",
              "         [0.26666668, 0.29411766, 0.28627452],\n",
              "         [0.27450982, 0.29803923, 0.29411766],\n",
              "         [0.30588236, 0.32941177, 0.32156864]],\n",
              "\n",
              "        [[0.41568628, 0.44313726, 0.4117647 ],\n",
              "         [0.3882353 , 0.41568628, 0.38431373],\n",
              "         [0.37254903, 0.4       , 0.36862746],\n",
              "         ...,\n",
              "         [0.30588236, 0.33333334, 0.3254902 ],\n",
              "         [0.30980393, 0.33333334, 0.3254902 ],\n",
              "         [0.3137255 , 0.3372549 , 0.32941177]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.10980392, 0.13725491, 0.15294118],\n",
              "         [0.11764706, 0.13333334, 0.17254902],\n",
              "         [0.12941177, 0.17254902, 0.18431373],\n",
              "         ...,\n",
              "         [0.16862746, 0.21960784, 0.1764706 ],\n",
              "         [0.20392157, 0.2509804 , 0.20784314],\n",
              "         [0.18039216, 0.22745098, 0.18431373]],\n",
              "\n",
              "        [[0.10588235, 0.11764706, 0.14901961],\n",
              "         [0.10588235, 0.10980392, 0.16078432],\n",
              "         [0.08235294, 0.12156863, 0.15294118],\n",
              "         ...,\n",
              "         [0.4392157 , 0.53333336, 0.38039216],\n",
              "         [0.45882353, 0.54901963, 0.39607844],\n",
              "         [0.4509804 , 0.5411765 , 0.39215687]],\n",
              "\n",
              "        [[0.13333334, 0.14117648, 0.16470589],\n",
              "         [0.12941177, 0.12941177, 0.16862746],\n",
              "         [0.09411765, 0.11764706, 0.15686275],\n",
              "         ...,\n",
              "         [0.6862745 , 0.8156863 , 0.56078434],\n",
              "         [0.69411767, 0.81960785, 0.5647059 ],\n",
              "         [0.6901961 , 0.8156863 , 0.56078434]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.5568628 , 0.6901961 , 0.4627451 ],\n",
              "         [0.5568628 , 0.6901961 , 0.4627451 ],\n",
              "         [0.5882353 , 0.72156864, 0.49803922],\n",
              "         ...,\n",
              "         [0.5254902 , 0.6862745 , 0.46666667],\n",
              "         [0.5019608 , 0.65882355, 0.4392157 ],\n",
              "         [0.5254902 , 0.6862745 , 0.46666667]],\n",
              "\n",
              "        [[0.54901963, 0.6901961 , 0.4862745 ],\n",
              "         [0.5686275 , 0.7058824 , 0.5058824 ],\n",
              "         [0.5882353 , 0.7294118 , 0.5254902 ],\n",
              "         ...,\n",
              "         [0.5137255 , 0.6666667 , 0.46666667],\n",
              "         [0.50980395, 0.6666667 , 0.46666667],\n",
              "         [0.47843137, 0.63529414, 0.43529412]],\n",
              "\n",
              "        [[0.5254902 , 0.67058825, 0.48235294],\n",
              "         [0.53333336, 0.67058825, 0.4862745 ],\n",
              "         [0.53333336, 0.67058825, 0.4862745 ],\n",
              "         ...,\n",
              "         [0.41568628, 0.5647059 , 0.39215687],\n",
              "         [0.40784314, 0.5568628 , 0.3882353 ],\n",
              "         [0.39607844, 0.54901963, 0.3764706 ]]],\n",
              "\n",
              "\n",
              "       [[[0.5254902 , 0.7294118 , 0.8745098 ],\n",
              "         [0.5137255 , 0.72156864, 0.8627451 ],\n",
              "         [0.5019608 , 0.7137255 , 0.85490197],\n",
              "         ...,\n",
              "         [0.49803922, 0.70980394, 0.87058824],\n",
              "         [0.49803922, 0.70980394, 0.87058824],\n",
              "         [0.5019608 , 0.7137255 , 0.8745098 ]],\n",
              "\n",
              "        [[0.52156866, 0.7411765 , 0.89411765],\n",
              "         [0.5058824 , 0.7294118 , 0.8784314 ],\n",
              "         [0.5019608 , 0.7294118 , 0.8784314 ],\n",
              "         ...,\n",
              "         [0.49803922, 0.7176471 , 0.8784314 ],\n",
              "         [0.49803922, 0.7176471 , 0.8784314 ],\n",
              "         [0.5019608 , 0.72156864, 0.88235295]],\n",
              "\n",
              "        [[0.5019608 , 0.7254902 , 0.8862745 ],\n",
              "         [0.49803922, 0.7137255 , 0.8745098 ],\n",
              "         [0.5019608 , 0.7137255 , 0.8745098 ],\n",
              "         ...,\n",
              "         [0.49411765, 0.70980394, 0.87058824],\n",
              "         [0.49411765, 0.70980394, 0.87058824],\n",
              "         [0.49411765, 0.7058824 , 0.8666667 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.68235296, 0.8156863 , 0.92156863],\n",
              "         [0.67058825, 0.80784315, 0.8980392 ],\n",
              "         [0.60784316, 0.7411765 , 0.84705883],\n",
              "         ...,\n",
              "         [0.10588235, 0.36862746, 0.53333336],\n",
              "         [0.11372549, 0.3764706 , 0.5372549 ],\n",
              "         [0.10980392, 0.36862746, 0.53333336]],\n",
              "\n",
              "        [[0.7607843 , 0.8666667 , 0.95686275],\n",
              "         [0.7411765 , 0.84313726, 0.9372549 ],\n",
              "         [0.62352943, 0.76862746, 0.88235295],\n",
              "         ...,\n",
              "         [0.11764706, 0.37254903, 0.5411765 ],\n",
              "         [0.11764706, 0.3764706 , 0.54509807],\n",
              "         [0.11764706, 0.37254903, 0.54901963]],\n",
              "\n",
              "        [[0.75686276, 0.8509804 , 0.92941177],\n",
              "         [0.70980394, 0.8156863 , 0.9019608 ],\n",
              "         [0.65882355, 0.7882353 , 0.8901961 ],\n",
              "         ...,\n",
              "         [0.12156863, 0.36862746, 0.53333336],\n",
              "         [0.1254902 , 0.36862746, 0.5372549 ],\n",
              "         [0.1254902 , 0.36862746, 0.5411765 ]]],\n",
              "\n",
              "\n",
              "       [[[0.49019608, 0.49019608, 0.45490196],\n",
              "         [0.43137255, 0.39607844, 0.35686275],\n",
              "         [0.4       , 0.3529412 , 0.3254902 ],\n",
              "         ...,\n",
              "         [0.7921569 , 0.8117647 , 0.8392157 ],\n",
              "         [0.78431374, 0.8039216 , 0.83137256],\n",
              "         [0.7921569 , 0.8156863 , 0.8392157 ]],\n",
              "\n",
              "        [[0.5568628 , 0.57254905, 0.5568628 ],\n",
              "         [0.57254905, 0.5647059 , 0.54509807],\n",
              "         [0.6901961 , 0.6745098 , 0.6666667 ],\n",
              "         ...,\n",
              "         [0.7647059 , 0.7882353 , 0.8039216 ],\n",
              "         [0.7764706 , 0.8039216 , 0.81960785],\n",
              "         [0.8       , 0.827451  , 0.84313726]],\n",
              "\n",
              "        [[0.7058824 , 0.7254902 , 0.7176471 ],\n",
              "         [0.56078434, 0.57254905, 0.57254905],\n",
              "         [0.6117647 , 0.6156863 , 0.6156863 ],\n",
              "         ...,\n",
              "         [0.47843137, 0.43529412, 0.44313726],\n",
              "         [0.54509807, 0.5019608 , 0.5137255 ],\n",
              "         [0.61960787, 0.5764706 , 0.5882353 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40784314, 0.32156864, 0.16078432],\n",
              "         [0.39607844, 0.3137255 , 0.15294118],\n",
              "         [0.39607844, 0.31764707, 0.14901961],\n",
              "         ...,\n",
              "         [0.49411765, 0.40392157, 0.2627451 ],\n",
              "         [0.49411765, 0.40392157, 0.27058825],\n",
              "         [0.49019608, 0.39607844, 0.26666668]],\n",
              "\n",
              "        [[0.40784314, 0.31764707, 0.15686275],\n",
              "         [0.4117647 , 0.32941177, 0.16078432],\n",
              "         [0.42745098, 0.34509805, 0.16862746],\n",
              "         ...,\n",
              "         [0.5411765 , 0.44313726, 0.30588236],\n",
              "         [0.5372549 , 0.44313726, 0.3137255 ],\n",
              "         [0.5372549 , 0.4392157 , 0.31764707]],\n",
              "\n",
              "        [[0.4117647 , 0.3254902 , 0.16470589],\n",
              "         [0.42352942, 0.34117648, 0.1764706 ],\n",
              "         [0.4509804 , 0.36862746, 0.19607843],\n",
              "         ...,\n",
              "         [0.56078434, 0.45882353, 0.32156864],\n",
              "         [0.56078434, 0.45490196, 0.32941177],\n",
              "         [0.5647059 , 0.45490196, 0.3372549 ]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get('units'))\n",
        "print (best_hps.get('learning_rate'))\n"
      ],
      "metadata": {
        "id": "h33gv8TeY3v2",
        "outputId": "6ef9bfc3-cefc-4752-b0c9-739ba808265b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
            "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
            "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
            "    return model.fit(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filekfr3r9qw.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n",
            "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n",
            "        return backend.sparse_categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n",
            "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
            "\n",
            "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32, 10)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-198649ad978f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_hps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'units'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filekfr3r9qw.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32, 10)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
        "\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
        "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
        "is {best_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "4bZwrkGuCsWn",
        "outputId": "4c9819a5-2af2-44d1-847b-ca420dd349f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 Complete [00h 00m 02s]\n",
            "\n",
            "Best val_accuracy So Far: None\n",
            "Total elapsed time: 00h 00m 03s\n",
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "416               |352               |units\n",
            "0.01              |0.001             |learning_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "3                 |3                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n",
            "    return super().run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
            "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
            "    return model.fit(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filekfr3r9qw.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n",
            "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n",
            "        return backend.sparse_categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n",
            "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
            "\n",
            "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32, 10)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bdceb1c1c21b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstop_early\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get the optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\", line 427, in run_trial\n    return super().run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filekfr3r9qw.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32, 10)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = keras_tuner.RandomSearch(\n",
        "    build_model,\n",
        "    objective='accuracy',\n",
        "    max_trials=3)"
      ],
      "metadata": {
        "id": "TxM3x61t-q1N"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=2,  validation_split=0.2)\n",
        "best_model = tuner.get_best_models(num_trials=1)[0]\n"
      ],
      "metadata": {
        "id": "CrNcySj1-wtH",
        "outputId": "df529ace-6f3c-4ab9-b9a8-19e15df76514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n",
            "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
            "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
            "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
            "    return model.fit(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n",
            "    raise e.with_traceback(filtered_tb) from None\n",
            "  File \"/tmp/__autograph_generated_filesw3tvx6o.py\", line 15, in tf__train_function\n",
            "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
            "ValueError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n",
            "        return step_function(self, iterator)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n",
            "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n",
            "        outputs = model.train_step(data)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n",
            "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n",
            "        return self.compiled_loss(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n",
            "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n",
            "        losses = call_fn(y_true, y_pred)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n",
            "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n",
            "        return backend.sparse_categorical_crossentropy(\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n",
            "        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
            "\n",
            "    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32768, 1)\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bcb676c3339c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    544\u001b[0m                     \u001b[0;34m\"Number of consecutive failures exceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/tmp/__autograph_generated_filesw3tvx6o.py\", line 15, in tf__train_function\n    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\nValueError: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2454, in sparse_categorical_crossentropy\n        return backend.sparse_categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5775, in sparse_categorical_crossentropy\n        res = tf.nn.sparse_softmax_cross_entropy_with_logits(\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(320,) and logits.shape=(32768, 1)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUjFcbw2y_3H"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<div style=\"direction:rtl;text-align:right;font-family:B Lotus, B Nazanin, Tahoma\"> دوره مقدماتی یادگیری عمیق<br>علیرضا اخوان پور<br>پنج شنبه، ۱۸ و ۲۵ بهمن ۱۳۹۷<br>\n",
        "</div>\n",
        "<a href=\"http://class.vision\">Class.Vision</a> - <a href=\"http://AkhavanPour.ir\">AkhavanPour.ir</a> - <a href=\"https://github.com/Alireza-Akhavan/\">GitHub</a>\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1VL647DW9tgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9fyGW7ty_3H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}